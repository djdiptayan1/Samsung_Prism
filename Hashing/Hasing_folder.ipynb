{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imagehash\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "california_images = \"../California/Photos_copy\"\n",
    "custom_images = \"../My_Image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    try:\n",
    "        # Read the image\n",
    "        img = cv2.imread(image_path)\n",
    "\n",
    "        # Resize the image\n",
    "        img = cv2.resize(img, (64, 64))\n",
    "\n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply a slight blur\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "        # Histogram equalization\n",
    "        equalized = cv2.equalizeHist(blurred)\n",
    "\n",
    "        # Normalize pixel values\n",
    "        normalized = equalized / 255.0\n",
    "\n",
    "        return normalized\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptual_hash(image):\n",
    "    # Preprocess the image\n",
    "    processed_image = preprocess_image(image)\n",
    "\n",
    "    # Create a pHash using imagehash library\n",
    "    hash_value = imagehash.phash(Image.fromarray((processed_image * 255).astype('uint8')))\n",
    "    \n",
    "    return hash_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicates_phash(folder_path, threshold=5):\n",
    "    hash_dict = {}\n",
    "    duplicate_groups = {}\n",
    "    total_images = 0\n",
    "\n",
    "    for image_path in Path(folder_path).glob('*.*'):\n",
    "        if image_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
    "            total_images += 1\n",
    "            hash_value = perceptual_hash(str(image_path))\n",
    "\n",
    "            # Check for near-duplicates within a threshold\n",
    "            for existing_hash, existing_image_paths in hash_dict.items():\n",
    "                if hash_value - existing_hash < threshold:\n",
    "                    existing_image_paths.append(image_path)\n",
    "                    duplicate_groups[hash_value] = existing_image_paths\n",
    "\n",
    "            hash_dict[hash_value] = [image_path]\n",
    "\n",
    "    return duplicate_groups, total_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_unique_duplicates(duplicate_groups):\n",
    "    for hash_value, image_paths in duplicate_groups.items():\n",
    "        num_images = len(image_paths)\n",
    "\n",
    "        # Create a matplotlib figure for consolidated display\n",
    "        plt.figure(figsize=(5 * num_images, 5))\n",
    "\n",
    "        for i, image_path in enumerate(image_paths, 1):\n",
    "            # Load the image using cv2\n",
    "            img = cv2.imread(str(image_path))\n",
    "\n",
    "            # Check if image is loaded successfully\n",
    "            if img is not None:\n",
    "                # Convert to RGB for matplotlib compatibility\n",
    "                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Add subplot using matplotlib\n",
    "                plt.subplot(1, num_images, i)\n",
    "                plt.imshow(img_rgb)\n",
    "                plt.title(f'Image {i}: {image_path.name}')\n",
    "            else:\n",
    "                print(f\"Error: Failed to load image {image_path.name}\")\n",
    "\n",
    "        plt.show()  # Display the figure with all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    folder_path = california_images\n",
    "    duplicate_groups, total_images = find_duplicates_phash(folder_path)\n",
    "    duplicates_folder = \"../duplicates\"\n",
    "\n",
    "    if duplicate_groups:\n",
    "        print(f\"Found {len(duplicate_groups)} groups of duplicate images\")\n",
    "        duplicate_images_count = sum([len(images) - 1 for images in duplicate_groups.values()])\n",
    "        print(f\"Total number of images: {total_images}\")\n",
    "        print(f\"Number of unique images: {total_images - duplicate_images_count}\")\n",
    "        print(f\"Number of duplicate images: {duplicate_images_count}\")\n",
    "        display_unique_duplicates(duplicate_groups)\n",
    "    else:\n",
    "        print(\"No duplicate images found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
