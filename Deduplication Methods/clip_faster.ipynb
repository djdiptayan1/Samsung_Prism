{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPENDENCIES LOADED\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageOps\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import tensorflow as tf\n",
    "from sklearn.cluster import DBSCAN\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "total_start = time()\n",
    "print(\"DEPENDENCIES LOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL LOADED\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "print(\"MODEL LOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess images in parallel\n",
    "def load_and_process_image(path):\n",
    "    image = Image.open(path)\n",
    "    image = ImageOps.fit(image, (224, 224))  # Resize to 224x224\n",
    "    image = np.array(image)\n",
    "    image = torch.tensor(image, dtype=torch.float32)\n",
    "    image = tf.constant(image.numpy(), dtype=tf.float32)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(demo_directory):\n",
    "    image_paths = [image_path for image_path in demo_directory.iterdir() if image_path.suffix.lower() in ['.jpg', '.jpeg', '.png']]\n",
    "\n",
    "    # Load and preprocess images in parallel\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        images = list(executor.map(load_and_process_image, image_paths))\n",
    "\n",
    "    images_to_paths = {image_path.stem: image_path for image_path in image_paths}\n",
    "\n",
    "    # Generate image embeddings in batches\n",
    "    batch_size = 32\n",
    "    outputs = []\n",
    "\n",
    "    for i in range(0, len(images), batch_size):\n",
    "        batch = images[i:i + batch_size]\n",
    "        inputs = processor(images=batch, return_tensors=\"pt\", padding=True).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs_batch = model.get_image_features(**inputs)\n",
    "            outputs.extend(outputs_batch.cpu().numpy())\n",
    "\n",
    "    images_to_embeddings = {image_id: embedding for image_id, embedding in zip(images_to_paths.keys(), outputs)}\n",
    "\n",
    "    return images_to_embeddings, images_to_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_duplicates(images_to_embeddings, images_to_paths, demo_directory, output_folder):\n",
    "    # Cluster embeddings using DBSCAN\n",
    "    image_ids = list(images_to_embeddings.keys())\n",
    "    embeddings = list(images_to_embeddings.values())\n",
    "    clustering = DBSCAN(min_samples=2, eps=3).fit(np.stack(embeddings))\n",
    "\n",
    "    image_id_communities = defaultdict(set)\n",
    "    independent_image_ids = set()\n",
    "\n",
    "    for image_id, cluster_idx in zip(image_ids, clustering.labels_):\n",
    "        cluster_idx = int(cluster_idx)\n",
    "        if cluster_idx == -1:\n",
    "            independent_image_ids.add(image_id)\n",
    "        else:\n",
    "            image_id_communities[cluster_idx].add(image_id)\n",
    "\n",
    "    output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    # Move duplicate images to the output folder\n",
    "    for cluster_idx, image_ids in image_id_communities.items():\n",
    "        if len(image_ids) > 1:  # Only move images if there are duplicates in the cluster\n",
    "            for image_id in image_ids:\n",
    "                # to copy use \"copy\", to move use \"move\"\n",
    "                shutil.copy(images_to_paths[image_id], output_folder / f\"{image_id}.jpg\")\n",
    "\n",
    "    print(f\"Total duplicate images moved: {sum(len(ids) for ids in image_id_communities.values() if len(ids) > 1)}\")\n",
    "    print(f\"Output folder: {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Display_images(output_folder):\n",
    "    image_paths = list(output_folder.glob(\"*.jpg\"))\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        image = Image.open(image_path)\n",
    "        plt.figure()\n",
    "        plt.imshow(image)\n",
    "        plt.title(image_path.stem)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicate images moved: 7056\n",
      "Output folder: ../duplicates\n",
      "TIme to compute duplicates:  51.68691420555115 Seconds\n",
      "TOTAL TIME TAKEN AFTER IMPORTING FILES:  55.212100982666016 Seconds\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Define image directory\n",
    "    demo_directory = Path(\"../coil-100\")\n",
    "    # demo_directory = Path(\"../My_Image\")\n",
    "    \n",
    "    output_folder = Path(\"../duplicates\")\n",
    "    \n",
    "    start_time = time()\n",
    "\n",
    "    # Process images from the directory\n",
    "    images_to_embeddings, images_to_paths = process_images(demo_directory)\n",
    "\n",
    "    # Handle duplicates\n",
    "    handle_duplicates(images_to_embeddings, images_to_paths, demo_directory, output_folder)\n",
    "    \n",
    "    end_time = time()\n",
    "    print(\"TIme to compute duplicates: \", end_time-start_time, \"Seconds\")\n",
    "    \n",
    "    total_end = time()\n",
    "    print(\"TOTAL TIME TAKEN AFTER IMPORTING FILES: \",total_end-total_start, \"Seconds\")\n",
    "    \n",
    "    dispimg = input(\"Do you want to display the images?\")\n",
    "    if (dispimg == 'y'):\n",
    "        Display_images(output_folder)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
